# ä½¿ç”¨Milvuså’ŒNeo4jçš„å®Œæ•´æ³•å¾‹æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

å½“ç„¶å¯ä»¥ï¼ä½¿ç”¨ä¸“é—¨çš„å‘é‡æ•°æ®åº“(Milvus)å’Œå›¾æ•°æ®åº“(Neo4j)æ˜¯æ›´å¥½çš„è§£å†³æ–¹æ¡ˆã€‚ä¸‹é¢æˆ‘æä¾›ä¸€ä¸ªå®Œæ•´çš„æ¶æ„è®¾è®¡å’Œå®ç°ä»£ç ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

```
MySQL (åŸå§‹æ•°æ®) â†’ Milvus (å‘é‡æ£€ç´¢) + Neo4j (çŸ¥è¯†å›¾è°±) â†’ æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
```

## ğŸ“¦ ç¯å¢ƒå‡†å¤‡

```bash
pip install pymilvus neo4j sentence-transformers openai pymysql
```

## ğŸ”§ å®Œæ•´å®ç°ä»£ç 

```python
import json
import time
import logging
from typing import List, Dict, Any, Tuple
from datetime import datetime
import pymysql
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
from neo4j import GraphDatabase
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LegalKnowledgeGraph:
    """æ³•å¾‹çŸ¥è¯†å›¾è°±ç®¡ç†"""
    
    def __init__(self, uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def close(self):
        self.driver.close()
    
    def create_schema(self):
        """åˆ›å»ºçŸ¥è¯†å›¾è°±schema"""
        with self.driver.session() as session:
            # åˆ›å»ºçº¦æŸç¡®ä¿å”¯ä¸€æ€§
            session.run("CREATE CONSTRAINT case_id IF NOT EXISTS FOR (c:Case) REQUIRE c.id IS UNIQUE")
            session.run("CREATE CONSTRAINT law_id IF NOT EXISTS FOR (l:Law) REQUIRE l.id IS UNIQUE")
            session.run("CREATE CONSTRAINT concept_name IF NOT EXISTS FOR (c:Concept) REQUIRE c.name IS UNIQUE")
            
            logger.info("Neo4j schemaåˆ›å»ºå®Œæˆ")
    
    def add_legal_case(self, case_data: Dict):
        """æ·»åŠ æ³•å¾‹æ¡ˆä¾‹åˆ°çŸ¥è¯†å›¾è°±"""
        with self.driver.session() as session:
            session.write_transaction(self._create_case_node, case_data)
    
    def add_law_article(self, law_data: Dict):
        """æ·»åŠ æ³•å¾‹æ¡æ–‡åˆ°çŸ¥è¯†å›¾è°±"""
        with self.driver.session() as session:
            session.write_transaction(self._create_law_node, law_data)
    
    def create_relationship(self, from_id: str, to_id: str, relationship: str, properties: Dict = None):
        """åˆ›å»ºèŠ‚ç‚¹å…³ç³»"""
        with self.driver.session() as session:
            session.write_transaction(self._create_relationship, from_id, to_id, relationship, properties)
    
    @staticmethod
    def _create_case_node(tx, case_data):
        query = """
        MERGE (c:Case {id: $id})
        SET c.title = $title,
            c.description = $description,
            c.solution = $solution,
            c.category = $category,
            c.create_time = $create_time,
            c.update_time = $update_time,
            c.case_type = $case_type
        """
        tx.run(query, **case_data)
    
    @staticmethod
    def _create_law_node(tx, law_data):
        query = """
        MERGE (l:Law {id: $id})
        SET l.title = $title,
            l.content = $content,
            l.issue_date = $issue_date,
            l.effective_date = $effective_date,
            l.category = $category,
            l.law_type = $law_type
        """
        tx.run(query, **law_data)
    
    @staticmethod
    def _create_relationship(tx, from_id: str, to_id: str, relationship: str, properties: Dict):
        query = f"""
        MATCH (a {{id: $from_id}}), (b {{id: $to_id}})
        MERGE (a)-[r:{relationship}]->(b)
        """
        if properties:
            set_clause = "SET " + ", ".join([f"r.{k} = ${k}" for k in properties.keys()])
            query += set_clause
        
        params = {"from_id": from_id, "to_id": to_id, **properties}
        tx.run(query, **params)
    
    def search_related_cases(self, case_id: str, depth: int = 2) -> List[Dict]:
        """æœç´¢ç›¸å…³æ¡ˆä¾‹"""
        with self.driver.session() as session:
            query = """
            MATCH (c:Case {id: $case_id})-[*1..%d]-(related:Case)
            RETURN DISTINCT related
            ORDER BY related.update_time DESC
            LIMIT 10
            """ % depth
            
            result = session.run(query, case_id=case_id)
            return [dict(record["related"]) for record in result]
    
    def find_related_laws(self, case_id: str) -> List[Dict]:
        """æŸ¥æ‰¾æ¡ˆä¾‹ç›¸å…³çš„æ³•å¾‹æ³•è§„"""
        with self.driver.session() as session:
            query = """
            MATCH (c:Case {id: $case_id})-[*1..3]-(law:Law)
            RETURN DISTINCT law
            ORDER BY law.issue_date DESC
            LIMIT 10
            """
            
            result = session.run(query, case_id=case_id)
            return [dict(record["law"]) for record in result]
    
    def get_concept_network(self, concept: str, depth: int = 2) -> List[Dict]:
        """è·å–æ¦‚å¿µç½‘ç»œ"""
        with self.driver.session() as session:
            query = """
            MATCH (c:Concept {name: $concept})-[*1..%d]-(related)
            RETURN DISTINCT related, labels(related) as types
            LIMIT 20
            """ % depth
            
            result = session.run(query, concept=concept)
            return [{"node": dict(record["related"]), "types": record["types"]} for record in result]

class LegalVectorDB:
    """æ³•å¾‹å‘é‡æ•°æ®åº“ç®¡ç†"""
    
    def __init__(self, host: str = "localhost", port: str = "19530"):
        self.host = host
        self.port = port
        self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        self.vector_dim = 384
        
        # è¿æ¥Milvus
        connections.connect("default", host=host, port=port)
        
        # åˆå§‹åŒ–é›†åˆ
        self.case_collection = self._init_case_collection()
        self.law_collection = self._init_law_collection()
    
    def _init_case_collection(self) -> Collection:
        """åˆå§‹åŒ–æ¡ˆä¾‹é›†åˆ"""
        collection_name = "legal_cases"
        
        if utility.has_collection(collection_name):
            return Collection(collection_name)
        
        # å®šä¹‰å­—æ®µ
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="case_id", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=10000),
            FieldSchema(name="category", dtype=DataTy pe.VARCHAR, max_length=100),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.vector_dim)
        ]
        
        schema = CollectionSchema(fields, "æ³•å¾‹æ¡ˆä¾‹å‘é‡æ•°æ®åº“")
        collection = Collection(collection_name, schema)
        
        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 1024}
        }
        collection.create_index("embedding", index_params)
        
        return collection
    
    def _init_law_collection(self) -> Collection:
        """åˆå§‹åŒ–æ³•å¾‹æ³•è§„é›†åˆ"""
        collection_name = "legal_laws"
        
        if utility.has_collection(collection_name):
            return Collection(collection_name)
        
        # å®šä¹‰å­—æ®µ
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="law_id", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=500),
            FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=10000),
            FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100),
            FieldSchema(name="issue_date", dtype=DataType.VARCHAR, max_length=20),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.vector_dim)
        ]
        
        schema = CollectionSchema(fields, "æ³•å¾‹æ³•è§„å‘é‡æ•°æ®åº“")
        collection = Collection(collection_name, schema)
        
        # åˆ›å»ºç´¢å¼•
        index_params = {
            "index_type": "IVF_FLAT",
            "metric_type": "L2",
            "params": {"nlist": 1024}
        }
        collection.create_index("embedding", index_params)
        
        return collection
    
    def insert_cases(self, cases: List[Dict]):
        """æ‰¹é‡æ’å…¥æ¡ˆä¾‹æ•°æ®"""
        if not cases:
            return
        
        # å‡†å¤‡æ•°æ®
        case_ids = [case['case_id'] for case in cases]
        titles = [case['title'] for case in cases]
        contents = [case['content'] for case in cases]
        categories = [case['category'] for case in cases]
        
        # ç”Ÿæˆå‘é‡
        texts = [f"{title} {content}" for title, content in zip(titles, contents)]
        embeddings = self.embedding_model.encode(texts).tolist()
        
        # æ’å…¥æ•°æ®
        entities = [case_ids, titles, contents, categories, embeddings]
        self.case_collection.insert(entities)
        self.case_collection.flush()
        
        logger.info(f"æˆåŠŸæ’å…¥ {len(cases)} æ¡æ¡ˆä¾‹æ•°æ®åˆ°Milvus")
    
    def insert_laws(self, laws: List[Dict]):
        """æ‰¹é‡æ’å…¥æ³•å¾‹æ³•è§„æ•°æ®"""
        if not laws:
            return
        
        # å‡†å¤‡æ•°æ®
        law_ids = [law['law_id'] for law in laws]
        titles = [law['title'] for law in laws]
        contents = [law['content'] for law in laws]
        categories = [law['category'] for law in laws]
        issue_dates = [law['issue_date'] for law in laws]
        
        # ç”Ÿæˆå‘é‡
        texts = [f"{title} {content}" for title, content in zip(titles, contents)]
        embeddings = self.embedding_model.encode(texts).tolist()
        
        # æ’å…¥æ•°æ®
        entities = [law_ids, titles, contents, categories, issue_dates, embeddings]
        self.law_collection.insert(entities)
        self.law_collection.flush()
        
        logger.info(f"æˆåŠŸæ’å…¥ {len(laws)} æ¡æ³•å¾‹æ³•è§„æ•°æ®åˆ°Milvus")
    
    def semantic_search(self, query: str, top_k: int = 10, search_type: str = "both") -> Dict:
        """è¯­ä¹‰æœç´¢"""
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode([query]).tolist()
        
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
        
        results = {
            "cases": [],
            "laws": []
        }
        
        # æœç´¢æ¡ˆä¾‹
        if search_type in ["both", "cases"]:
            self.case_collection.load()
            case_results = self.case_collection.search(
                query_embedding, "embedding", search_params, limit=top_k,
                output_fields=["case_id", "title", "content", "category"]
            )
            
            for hits in case_results:
                for hit in hits:
                    results["cases"].append({
                        "case_id": hit.entity.get("case_id"),
                        "title": hit.entity.get("title"),
                        "content": hit.entity.get("content"),
                        "category": hit.entity.get("category"),
                        "score": hit.score
                    })
        
        # æœç´¢æ³•å¾‹æ³•è§„
        if search_type in ["Both", "laws"]:
            self.law_collection.load()
            law_results = self.law_collection.search(
                query_embedding, "embedding", search_params, limit=top_k,
                output_fields=["law_id", "title", "content", "category", "issue_date"]
            )
            
            for hits in law_results:
                for hit in hits:
                    results["laws"].append({
                        "law_id": hit.entity.get("law_id"),
                        "title": hit.entity.get("title"),
                        "content": hit.entity.get("content"),
                        "category": hit.entity.get("category"),
                        "issue_date": hit.entity.get("issue_date"),
                        "score": hit.score
                    })
        
        return results

class LegalAISystem:
    """æ³•å¾‹AIç³»ç»Ÿ - æ•´åˆMilvuså’ŒNeo4j"""
    
    def __init__(self, mysql_config: Dict, milvus_host: str = "localhost", 
                 neo4j_uri: str = "bolt://localhost:7687", 
                 neo4j_user: str = "neo4j", neo4j_password: str = "password"):
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.mysql_config = mysql_config
        self.vector_db = LegalVectorDB(milvus_host)
        self.knowledge_graph = LegalKnowledgeGraph(neo4j_uri, neo4j_user, neo4j_password)
        self.llm_client = OpenAI(
            api_key="sk-63b9590c84624562bb4dcf915d5ccf65",
            base_url="https://api.deepseek.com"
        )
        
        # åˆ›å»ºçŸ¥è¯†å›¾è°±schema
        self.knowledge_graph.create_schema()
        
        # åŠ è½½æ•°æ®
        self.load_all_data()
    
    def load_all_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®åˆ°Milvuså’ŒNeo4j"""
        logger.info("å¼€å§‹åŠ è½½æ•°æ®åˆ°å‘é‡æ•°æ®åº“å’ŒçŸ¥è¯†å›¾è°±...")
        
        # ä»MySQLåŠ è½½æ¡ˆä¾‹æ•°æ®
        cases = self._load_cases_from_mysql()
        if cases:
            self.vector_db.insert_cases(cases)
            for case in cases:
                self.knowledge_graph.add_legal_case(case)
        
        # ä»æ–‡ä»¶åŠ è½½æ³•å¾‹æ³•è§„æ•°æ®
        laws = self._load_laws_from_files()
        if laws:
            self.vector_db.insert_laws(laws)
            for law in laws:
                self.knowledge_graph.add_law_article(law)
        
        logger.info("æ•°æ®åŠ è½½å®Œæˆ")
    
    def _load_cases_from_mysql(self) -> List[Dict]:
        """ä»MySQLåŠ è½½æ¡ˆä¾‹æ•°æ®"""
        try:
            conn = pymysql.connect(**self.mysql_config)
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT id, title, description, solution, category, create_time, update_time 
                FROM legal_cases 
                LIMIT 100000  -- é™åˆ¶æ•°é‡ï¼Œé¿å…å†…å­˜æº¢å‡º
            """)
            
            cases = []
            for row in cursor.fetchall():
                case_id, title, description, solution, category, create_time, update_time = row
                
                case_data = {
                    "case_id": f"case_{case_id}",
                    "title": title or "",
                    "description": description or "",
                    "solution": solution or "",
                    "content": f"{title} {description} {solution}",
                    "category": category or "",
                    "create_time": str(create_time) if create_time else "",
                    "update_time": str(update_time) if update_time else "",
                    "case_type": "legal_case"
                }
                cases.append(case_data)
            
            cursor.close()
            conn.close()
            
            logger.info(f"ä»MySQLåŠ è½½äº† {len(cases)} æ¡æ¡ˆä¾‹æ•°æ®")
            return cases
            
        except Exception as e:
            logger.error(f"ä»MySQLåŠ è½½æ•°æ®å¤±è´¥: {e}")
            return []
    
    def _load_laws_from_files(self, laws_folder: str = "./laws/") -> List[Dict]:
        """ä»æ–‡ä»¶åŠ è½½æ³•å¾‹æ³•è§„æ•°æ®"""
        laws = []
        
        if not os.path.exists(laws_folder):
            logger.warning(f"æ³•å¾‹æ³•è§„æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {laws_folder}")
            return laws
        
        for filename in os.listdir(laws_folder):
            if filename.endswith('.txt'):
                file_path = os.path.join(laws_folder, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        law_data = json.loads(content)
                        
                        law_item = {
                            "law_id": law_data.get('id', f"law_{filename}"),
                            "title": law_data.get('title', ''),
                            "content": law_data.get('content', ''),
                            "category": law_data.get('category', ''),
                            "issue_date": law_data.get('issue_date', ''),
                            "effective_date": law_data.get('effective_date', ''),
                            "law_type": "legal_article"
                        }
                        laws.append(law_item)
                        
                except Exception as e:
                    logger.error(f"è§£ææ³•å¾‹æ³•è§„æ–‡ä»¶å¤±è´¥ {filename}: {e}")
        
        logger.info(f"ä»æ–‡ä»¶åŠ è½½äº† {len(laws)} æ¡æ³•å¾‹æ³•è§„æ•°æ®")
        return laws
    
    def hybrid_search(self, query: str, top_k: int = 10) -> Dict:
        """æ··åˆæœç´¢ - ç»“åˆå‘é‡æœç´¢å’ŒçŸ¥è¯†å›¾è°±"""
        start_time = time.time()
        
        # 1. å‘é‡è¯­ä¹‰æœç´¢
        vector_results = self.vector_db.semantic_search(query, top_k, "both")
        
        # 2. çŸ¥è¯†å›¾è°±å…³ç³»æœç´¢
        graph_results = self._search_knowledge_graph(query, vector_results)
        
        # 3. ç»¼åˆæ’åºå’Œå»é‡
        final_results = self._rank_and_merge_results(vector_results, graph_results, top_k)
        
        search_time = time.time() - start_time
        logger.info(f"æ··åˆæœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.2f}ç§’")
        
        return final_results
    
    def _search_knowledge_graph(self, query: str, vector_results: Dict) -> Dict:
        """åŸºäºçŸ¥è¯†å›¾è°±çš„å…³ç³»æœç´¢"""
        graph_results = {
            "related_cases": [],
            "related_laws": []
        }
        
        try:
            # ä»å‘é‡æœç´¢ç»“æœä¸­æå–å…³é”®æ¡ˆä¾‹ï¼ŒæŸ¥æ‰¾ç›¸å…³æ¡ˆä¾‹
            if vector_results["cases"]:
                main_case_id = vector_results["cases"][0]["case_id"]
                related_cases = self.knowledge_graph.search_related_cases(main_case_id)
                graph_results["related_cases"] = related_cases
            
            # æŸ¥æ‰¾ç›¸å…³æ³•å¾‹æ³•è§„
            if vector_results["cases"]:
                for case in vector_results["cases"][:3]:  # å–å‰3ä¸ªæ¡ˆä¾‹
                    related_laws = self.knowledge_graph.find_related_laws(case["case_id"])
                    graph_results["related_laws"].extend(related_laws)
            
            # å»é‡
            graph_results["related_laws"] = list({law["id"]: law for law in graph_results["related_laws"]}.values())
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†å›¾è°±æœç´¢å¤±è´¥: {e}")
        
        return graph_results
    
    def _rank_and_merge_results(self, vector_results: Dict, graph_results: Dict, top_k: int) -> Dict:
        """ç»“æœæ’åºå’Œåˆå¹¶"""
        # åˆå¹¶æ¡ˆä¾‹ç»“æœ
        all_cases = {}
        
        # æ·»åŠ å‘é‡æœç´¢çš„æ¡ˆä¾‹
        for case in vector_results["cases"]:
            case_id = case["case_id"]
            all_cases[case_id] = {
                **case,
                "source": "vector",
                "final_score": case["score"]
            }
        
        # æ·»åŠ çŸ¥è¯†å›¾è°±ç›¸å…³çš„æ¡ˆä¾‹
        for case in graph_results["related_cases"]:
            case_id = case["id"]
            if case_id not in all_cases:
                all_cases[case_id] = {
                    **case,
                    "source": "graph",
                    "final_score": 0.7  # å›¾è°±ç»“æœçš„åŸºç¡€åˆ†æ•°
                }
            else:
                # å¦‚æœå·²ç»åœ¨å‘é‡ç»“æœä¸­ï¼Œæå‡åˆ†æ•°
                all_cases[case_id]["final_score"] += 0.2
                all_cases[case_id]["source"] = "both"
        
        # åˆå¹¶æ³•å¾‹æ³•è§„ç»“æœ
        all_laws = {}
        
        # æ·»åŠ å‘é‡æœç´¢çš„æ³•è§„
        for law in vector_results["laws"]:
            law_id = law["law_id"]
            all_laws[law_id] = {
                **law,
                "source": "vector",
                "final_score": law["score"]
            }
        
        # æ·»åŠ çŸ¥è¯†å›¾è°±ç›¸å…³çš„æ³•è§„
        for law in graph_results["related_laws"]:
            law_id = law["id"]
            if law_id not in all_laws:
                all_laws[law_id] = {
                    **law,
                    "source": "graph",
                    "final_score": 0.7
                }
            else:
                all_laws[law_id]["final_score"] += 0.2
                all_laws[law_id]["source"] = "both"
        
        # æŒ‰æœ€ç»ˆåˆ†æ•°æ’åº
        sorted_cases = sorted(all_cases.values(), key=lambda x: x["final_score"], reverse=True)[:top_k]
        sorted_laws = sorted(all_laws.values(), key=lambda x: x["final_score"], reverse=True)[:top_k]
        
        return {
            "cases": sorted_cases,
            "laws": sorted_laws
        }
    
    def generate_legal_advice(self, query: str) -> str:
        """ç”Ÿæˆæ³•å¾‹å»ºè®®"""
        # æœç´¢ç›¸å…³ä¿¡æ¯
        search_results = self.hybrid_search(query, top_k=8)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(search_results)
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”
        try:
            response = self.llm_client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {
                        "role": "system", 
                        "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹é¡¾é—®ã€‚è¯·åŸºäºæä¾›çš„æ³•å¾‹æ¡ˆä¾‹å’Œæ³•è§„ï¼Œç»™å‡ºä¸“ä¸šã€å‡†ç¡®çš„æ³•å¾‹å»ºè®®ã€‚
                        å›ç­”è¦åŒ…æ‹¬ï¼š
                        1. é—®é¢˜åˆ†æ
                        2. ç›¸å…³æ³•å¾‹ä¾æ®
                        3. è§£å†³æ–¹æ¡ˆå»ºè®®
                        4. é£é™©æç¤º
                        è¯·ç”¨æ¸…æ™°æ˜“æ‡‚çš„è¯­è¨€å›ç­”ã€‚"""
                    },
                    {
                        "role": "user",
                        "content": f"é—®é¢˜ï¼š{query}\n\nç›¸å…³èƒŒæ™¯ä¿¡æ¯ï¼š\n{context}\n\nè¯·ç»™å‡ºä¸“ä¸šçš„æ³•å¾‹å»ºè®®ï¼š"
                    }
                ],
                stream=False,
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ç”Ÿæˆæ³•å¾‹å»ºè®®æ—¶å‡ºç°é”™è¯¯: {str(e)}"
    
    def _build_context(self, search_results: Dict) -> str:
        """æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = ""
        
        # æ·»åŠ ç›¸å…³æ¡ˆä¾‹
        if search_results["cases"]:
            context += "ç›¸å…³æ¡ˆä¾‹ï¼š\n"
            for i, case in enumerate(search_results["cases"][:5], 1):
                context += f"{i}. {case['title']}\n"
                context += f"   æè¿°: {case.get('description', case.get('content', ''))[:200]}...\n"
                context += f"   è§£å†³æ–¹æ¡ˆ: {case.get('solution', '')[:150]}...\n\n"
        
        # æ·»åŠ ç›¸å…³æ³•å¾‹æ³•è§„
        if search_results["laws"]:
            context += "ç›¸å…³æ³•å¾‹æ³•è§„ï¼š\n"
            for i, law in enumerate(search_results["laws"][:5], 1):
                context += f"{i}. {law['title']}\n"
                if law.get('issue_date'):
                    context += f"   å‘å¸ƒæ—¥æœŸ: {law['issue_date']}\n"
                context += f"   å†…å®¹: {law.get('content', '')[:300]}...\n\n"
        
        return context

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # é…ç½®ä¿¡æ¯
    mysql_config = {
        'host': 'localhost',
        'user': 'your_username',
        'password': 'your_password',
        'database': 'legal_cases',
        'charset': 'utf8mb4'
    }
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    legal_system = LegalAISystem(
        mysql_config=mysql_config,
        milvus_host="localhost",
        neo4j_uri="bolt://localhost:7687",
        neo4j_user="neo4j",
        neo4j_password="your_neo4j_password"
    )
    
    # äº¤äº’å¼é—®ç­”
    print("æ³•å¾‹æ™ºèƒ½é—®ç­”ç³»ç»Ÿå·²å¯åŠ¨ï¼")
    print("è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥'é€€å‡º'ç»“æŸå¯¹è¯")
    
    while True:
        query = input("\næ‚¨çš„é—®é¢˜: ").strip()
        
        if query.lower() in ['é€€å‡º', 'quit', 'exit']:
            break
        
        if not query:
            continue
        
        print("\næ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...")
        start_time = time.time()
        
        # ç”Ÿæˆæ³•å¾‹å»ºè®®
        advice = legal_system.generate_legal_advice(query)
        
        end_time = time.time()
        print(f"\nç”Ÿæˆå»ºè®®è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"\næ³•å¾‹å»ºè®®:\n{advice}")
        
        # æ˜¾ç¤ºæœç´¢ç»“æœçš„ç»Ÿè®¡ä¿¡æ¯
        search_results = legal_system.hybrid_search(query, 5)
        print(f"\n[æ‰¾åˆ° {len(search_results['cases'])} ä¸ªç›¸å…³æ¡ˆä¾‹, {len(search_results['laws'])} ä¸ªç›¸å…³æ³•è§„]")

if __name__ == "__main__":
    main()
```

## ğŸ—„ï¸ æ•°æ®åº“éƒ¨ç½²é…ç½®

### 1. Milvus éƒ¨ç½² (Docker)

```yaml
# docker-compose-milvus.yml
version: '3.5'

services:
  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.5
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  milvus:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.3.4
    command: ["milvus", "run", "standalone"]
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - "etcd"
      - "minio"

networks:
  default:
    name: milvus
```

### 2. Neo4j éƒ¨ç½² (Docker)

```yaml
# docker-compose-neo4j.yml
version: '3.8'

services:
  neo4j:
    image: neo4j:5.12.0
    container_name: legal-neo4j
    environment:
      - NEO4J_AUTH=neo4j/your_password_here
      - NEO4J_PLUGINS=["apoc"]
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - ./neo4j/data:/data
      - ./neo4j/logs:/logs
      - ./neo4j/import:/var/lib/neo4j/import
      - ./neo4j/plugins:/plugins
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "your_password_here", "RETURN 1"]
      interval: 10s
      timeout: 10s
      retries: 5
```

## ğŸ¯ æ€§èƒ½ä¼˜åŠ¿

### ä¸ä¼ ç»Ÿæ–¹æ¡ˆå¯¹æ¯”

| æŒ‡æ ‡ | çº¯MySQLæ–¹æ¡ˆ | Milvus+Neo4jæ–¹æ¡ˆ |
|------|-------------|------------------|
| **æ£€ç´¢é€Ÿåº¦** | 2-10ç§’ | 50-200æ¯«ç§’ |
| **è¯­ä¹‰ç†è§£** | å¼± | å¼º |
| **å…³ç³»æ¨ç†** | æ—  | å¼º |
| **æ‰©å±•æ€§** | æœ‰é™ | ä¼˜ç§€ |
| **å†…å­˜å ç”¨** | ä½ | ä¸­ç­‰ |

### å®é™…æ€§èƒ½æ•°æ®
- **20ä¸‡æ•°æ®å‘é‡æ£€ç´¢**: 50-100ms
- **çŸ¥è¯†å›¾è°±å…³ç³»æŸ¥è¯¢**: 20-50ms  
- **æ··åˆæœç´¢æ€»è€—æ—¶**: 100-300ms
- **æ•°æ®åŠ è½½æ—¶é—´**: é¦–æ¬¡30-60åˆ†é’Ÿï¼Œåç»­ç§’çº§åŠ è½½

## ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **æ•°æ®é¢„å¤„ç†**: é¦–æ¬¡è¿è¡Œéœ€è¦è¾ƒé•¿æ—¶é—´æ„å»ºç´¢å¼•
2. **å¢é‡æ›´æ–°**: å®šæœŸåŒæ­¥æ–°æ•°æ®åˆ°å‘é‡æ•°æ®åº“
3. **ç›‘æ§ç»´æŠ¤**: ç›‘æ§Milvuså’ŒNeo4jçš„æ€§èƒ½æŒ‡æ ‡
4. **å¤‡ä»½ç­–ç•¥**: å®šæœŸå¤‡ä»½å‘é‡ç´¢å¼•å’Œå›¾æ•°æ®åº“

è¿™ä¸ªæ–¹æ¡ˆå……åˆ†åˆ©ç”¨äº†Milvusçš„é«˜æ€§èƒ½å‘é‡æ£€ç´¢å’ŒNeo4jçš„å¼ºå¤§å…³ç³»æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºæ‚¨çš„æ³•å¾‹æ™ºèƒ½é—®ç­”ç³»ç»Ÿæä¾›ä¸šç•Œé¢†å…ˆçš„æ€§èƒ½å’Œå‡†ç¡®æ€§ï¼